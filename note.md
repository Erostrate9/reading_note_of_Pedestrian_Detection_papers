# A Shape Transformation-based Dataset Augmentation Framework for Pedestrian Detection

##  Abstract

## 1. Introduction

### 行人识别所遇到的问题

* deep convolutional neural networks (DCNNs) 深度卷积神经网络在行人识别中表现良好，但DCNNs识别器在遇到负背景比正前景突出的情况时可能会不够鲁棒。用有限前景样本训练的DCNN识别器面对未学习过的复杂测试物体会非常脆弱。
  * positive foreground or positive space 是图像中我们期望观察的主体，如行人。
  * negative background or negative space 是图像中主体以外的背景，如街道。

### 现有的解决方案

* 为了改善识别器的鲁棒性，数据增强是除设计新机器学习算法外的另一个解决方案。例如：
  * 像Stephan R. Richter等人用3D游戏GTA5识别生成图像数据集那样，Huang等人用一个3D游戏引擎生成行人，调整后加入训练集中。

  * 还有些研究使用了GANs，通过改变行人的姿势来扩充人重识别数据集。

### 存在的问题

* 但是上述的这些方法想要直接应用到行人识别是很困难的，因为：

1. 使用3D游戏引擎等外部平台合成行人可能会引入与真实行人间显著的域差距domain gap，总体上对鲁棒性的收益可能不大。
2. 关于利用GANs渲染行人的方法，这往往需要训练图像丰富的外观细节，以便于确定生成网络的期望输出，但真实的行人数据集（Caltech, CityPersons）往往图像质量低 （比如重度重叠，外观模糊，低分辨率），这些数据集只能提供非常少的能用于训练生成网络的外观细节，作者通过实验证明，在这些数据集中，现有的基于GAN的方法只能生成很少的真实行人，甚至产生了反作用。

### 对问题的观察

* 为了解决上述问题，作者建议通过根据不同形状（研究中的提到的segmentation mask）将来自同一数据集的真实行人转换成不同姿势，而不是渲染新的行人。这基于以下观察：
  1. 如果数据集只有低质量的行人示例可用，那么更容易获得丰富的像素级形状变换监督，该监督定义了从一个形态shape到另一个形态的变换。学习得到的变换可以指导真实行人外观的变换，同时避免了对定义变形后外观所需的细节监督信息的依赖。
  2. 由于形态shape信息可以自然地区分前景和背景，可以简单地将注意力集中在将合成的前景外观适配到背景环境中，即只生成前景，将原始背景与前景合成。这样就避免了目前一些GAN方法中在合成行人的同时制造不自然的背景环境的情况。
  3. 基于不同形状shape变换真实行人可以有效地增加前景的样本多样性，同时保持还能充分保持真实行人的外观特征。

### 解决方案

* 作者提出了一个基于形状变换的数据集增强框架——Shape Transformation based Dataset Augmentation (STDA)
* 图示：![](https://raw.githubusercontent.com/Erostrate9/img/main/20211213172947.png)
* 该框架首先将真实行人变形为相似但具有不同形状的行人，然后使变形的行人适应要增强的图像的背景。
  * 为了进一步定义形状和真实行人外观间一个合适的形状变换，作者引入了形状引导的变换场 shape-guided warping field，即一组定义了形状变换操作的向量。
  * 此外，作者还引入了环境感知混合映射来使变形后的行人更好的混合到多种背景场景中，这能产生看起来更真实的行人图像。

### 关键性贡献

1. 提出了一个STDA框架来扩充行人检测数据集，提高检测准确性。
2. 提出了形状引导变换场（shape-guided warping field）来定义适当的形状变换程序。引入了环境感知混合映射（environment-aware blending map）以让变形的行人适应到不同的背景中。
3. 引入形状约束操作来提高形状变换质量。应用了加大难分正样本挖掘损失函数（hard positive mining loss）以利用难分样本挖掘hard mining技术，同时进一步放大合成行人在提高检测鲁棒性上的优势。
   - 正样本：我们想要正确分类出的类别所对应的样本，例如，我们需要对一张图片分类，确定是否属于猫，那么在训练的时候，猫的图片就是正样本。
   - 负样本：根据上面的例子，不是猫的其他所有的图片都是负样本
   - 难分正样本(hard positives)：错分成负样本的正样本，也可以是训练过程中损失最高的正样本
   - 难分负样本(hard negatives)：错分成正样本的负样本，也可以是训练过程中损失最高的负样本
   - 易分正样本(easy positive)：容易正确分类的正样本，该类的概率最高。也可以是训练过程中损失最低的正样本
   - 易分负样本(easy negatives)：容易正确分类的负样本，该类的概率最高。也可以是训练过程中损失最低的负样本。
4. STDA框架不仅有利于分类识别，而且对于生成也是有希望的，框架可以生成更逼真的行人，提高检测器性能。

## 2. 相关工作

### 行人识别

前景和背景样本在数据集中极不平衡，对鲁棒性产生不利影响；目前的行人探测器仍可能脆弱，即使是面对很小的行人变形。为了解决这个问题，许多研究人员倾向于通过合成新的前景数据来扩充数据集。

### 基于模拟的数据增强

用3D模拟平台合成的新实例与真实行人有明显的域差距domain gap，目前有其他工作者使用GAN来改善但效果有限。

### 基于GAN的数据增强

许多工作试图转移真实行人的姿态，有研究者提出了根据不同姿态生成行人的新方法。但在实践中，这些方法往往需要准确可靠的姿态信息或包含丰富外观细节的配对训练图像才能实现成功的变换，然而已有的数据集（如Caltech）级部提供姿态注释也不提供用于训练GANs的配对外观信息。

此外，在当前的行人数据集中，大量外观质量较低的小型行人会使现有的姿态估计器难以提供合理的预测。图2显示了一些例子，描述了低质量行人的姿态（Pose）比使用相同的Mask RCNN 检测器估计的Shape/mask更不稳定（He et al. 2017）。因此，想要无缝地迁移应用这些姿态转移模型来扩充当前的行人数据集是非常不可行的。

总之，在这篇文章中，作者通过改变行人的形状，可以产生多样且真实的行人，且不需要使用GAN时所需的丰富外观细节。

## 3. Shape Transformation-based Dataset Augmentation Framework(STDA)

### 3.1 问题定义

#### 数据增强 Data Augmentation

数据增强技术，通常被表述为原始数据的转换，图像识别中的绝大多数最先进成果都是用了该技术。

数据增强被直观地解释为增加训练数据集的大小，并且作为一个可以模拟假设模型复杂性（Hypothesis complexity，即Hypothesis集合里模型的个数）的正则器。假设复杂度可以用来衡量泛化误差，即训练和测试误差之间的差异，或者说全局误差和局部误差之间的差异。较大的假设复杂性通常意味着较大的泛化误差。在实践中，减小训练误差和泛化误差有利于保证一个小的测试误差。因此，数据增强对深度学习模型特别有用，因为深度学习模型在保持小的训练误差方面很强大，但有很大的假设复杂性。经验证明，数据增强操作可以大大改善深度模型的泛化能力。

在这项研究中，总体目标是设计一个更有效的的数据增强框架，以改善行人检测模型。该框架通过将真实行人转换成不同形状而不是渲染新的行人来生成多样化、逼真的行人。

* 首先，利用变形操作，将行人的形状适当地变换为各种形状，以丰富行人的外观。变形引入适当的噪声来帮助正则化深度模型。
* 然后，应用充分的环境适应来更好地将生成的行人融入不同的背景区域。这个适应性工作最大限度减少了人工合成产生的不自然成分，同时保持了生成行人的外观多样性。
* 因此，该文章的方法可以有效地正则化假设复杂度，实验表明该方法可以显著提高基线检测性能，且优于其他增强方法。

形式上，假设$z_i$是一个包含数据集中真实行人的图像，$s_i$是其提取的形状或segmentation mask. 这里把行人$z_i$的形状或mask $s_i$称为一组标签，表示为$s_i(x，y)$，用于区分行人patch中的前景区域和背景区域，其中$(x，y)$代表图像上的坐标：$s_i(x，y)=1$表示位置$(x，y)$位于前景，$s_i(x，y)=0$表示位置$(x，y)$位于背景。将$s_j$表示为另一个不同的形状，它可以是从另一个真实行人的形状获得的。
在本研究中，作者实现了一个基于形状变换的数据集增强功能，表示为$f_{STDA}$，通过将一个有形状$s_i$的真实行人转化为有另一个形状$s_j$的新行人，使其具有更真实的外观，从而生成一个用于增强的新行人。

$z^{gen}_{i\rarr j}=f_{STDA}(z_i,s_i,s_j,I)$

其中$z^{gen}_{i\rarr j}$是一个包含新生成的行人$z_i$的patch，$z_i$的形状经过转换：$s_i\rarr s_j$，$I$是要被增强的图像。



### 框架概述



在行人检测数据集中很难获得足够的外观细节来定义$z^{gen}_{i\rarr j}$，为了正确实现框架，作者将行人生成任务分解为两个子任务：”形状引导的变形“和”环境适应“。

第一个任务的重点是改变外观以丰富数据的多样性，第二个任务主要是将变形的行人适应并融合到不同的环境中，可以形式化地表示为：

$z^{gen}_{i\rarr j}=f_{STDA}(z_i,s_i,s_j,I)=f_{EA}(f_{SD}(z_i,s_i,s_j),I)$

图3：![](https://raw.githubusercontent.com/Erostrate9/img/main/20211214192328.png)

图3显示了STDA的详细架构。

* 作者引入了一个形状引导变形场（shape-guided warping field），记作$V_{i\rarr j}$，以帮助实现形状引导变形函数。变形场被构造为图像平面上的向量分配，用于在形状之间进行变换。借助$V_{i\rarr j}$，不同形状之间的变形可以引导真实行人外观的改变。
* 作者还建议应用环境感知混合映射来实现环境适应，作者将混合影射定义为一组用来融合前景像素值和背景像素值的加权参数，作者使用$\alpha(x,y)$表示一个位于$(x,y)$的混合映射的条目。
* 在实践中，作者用了单个端到端的U-Net来帮助一次完成两个子任务。U-Net是使用多尺度特征进行语义分割任务的算法。
* 所采用的网络将行人块$z_i$，其形状$s_i$以及目标形状$s_j$和来自$I$的背景背景块作为输入，然后预测$V_{i\rarr j}$和$\alpha(x,y)$。
* 作者在实践中发现U-Net有能力联合学习这两个子任务，联合学习和单独学习两个子任务效果是一样的，同时大大简化了处理框架，节省了计算资源和所需参数。因此作者选择同时向U-Net提供所有必要的输入信息来融合两个函数的学习。

#### Shape-guided Deformation

作者用warping操作来实现变形，引入了形状引导变换场（*shape-guided warping field*）来描述该操作。用$v_{i\rarr j}(x,y)$表示位于$(x,y)$处的warping向量，变换场（warping field）就是这些向量的集合，i.e. $V_{i\rarr j}=\{v_{i\rarr j}(x,y)\}$。

如图4所示，变换场帮助$s_i(蓝色)变形为s_j(紫色)$

![](https://raw.githubusercontent.com/Erostrate9/img/main/20211214192245.png)

* 然后，假设$f_{warp}$是根据预测的变换场变换输入的图片块的函数，那么我们可以这样实现上文提到的$f_{SD}$:
  * $z^w_{i\rarr j}=f_{SD}(z_i,s_i,s_j)=f_{warp}(z_i;V_{i\rarr j})$
  * $z^w_{i\rarr j}$表示变换成形状$s_j$的行人$z_i$
  * 在实践中，作者定义每个变换向量$v_{i\rarr j}(x,y)$是一个二维向量，其中包含点在映射后的水平和垂直位移。
  * 作者使用网络直接预测$V_{i\rarr j}$。作者还使用了双线性插值帮助实现$f_{warp}$，双线性插值可以正确地将梯度从$z^w_{i\rarr j}$反向传播到$V_{i\rarr j}$。

假设$s^w_{i\rarr j}$是$s_i$经过$V_{i\rarr j}$变换得到的形状，由于不同形状可以很容易地从行人数据集中获取，所以能获得足够的像素级监督来训练一个网络，使用$L_1$距离（即$||s_j-s^w_{i\rarr j}||_1$来测量目标形状与所得形状的距离）作为训练损失，以学习所需的变形场，该场可以帮助生成基于$z^w_{i\rarr j}=f_{SD}(z_i,s_i,s_j)=f_{warp}(z_i;V_{i\rarr j})$所描述的形状变换得到的自然行人。

* $s_i与s_j$不能相差过大，否则会产生扭曲影响性能，作者引入了形状约束操作（*Shape Constraining Operation*），具体细节不展开讨论。

